# Result Fetcher ì„œë¹„ìŠ¤

## ğŸ“‹ ëª©í‘œ

ì¸ì¦ëœ ì‚¬ìš©ìì˜ ê²°ê³¼ë¥¼ ì¡°íšŒí•˜ëŠ” ì„œë¹„ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

---

## ğŸ”§ êµ¬í˜„

### íŒŒì¼: `app/services/result_fetcher.py`

```python
"""
Result Fetcher ì„œë¹„ìŠ¤
"""
from sqlalchemy.orm import Session
from typing import Dict
import logging
import json

from app.models.job import Job, JobStatus
from app.models.job_file import JobFile
from app.models.report import Report
from app.services.s3_service import S3Service
from app.core.exceptions import AppException

logger = logging.getLogger(__name__)


class ResultFetcher:
    """
    ê²°ê³¼ ì¡°íšŒ ì„œë¹„ìŠ¤
    """

    def __init__(self, db: Session):
        self.db = db
        self.s3_service = S3Service()

    def fetch_result(self, job_id: str) -> Dict:
        """
        Job ê²°ê³¼ ì¡°íšŒ

        Args:
            job_id: Job ID

        Returns:
            ê²°ê³¼ ë°ì´í„°
            {
                "job_id": str,
                "status": str,
                "files": List[dict],
                "report": dict | None,
                "expires_at": datetime
            }

        Raises:
            AppException(E-AUTH-001): Job ì—†ìŒ
            AppException(E-AUTH-005): Job ë§Œë£Œë¨
        """
        logger.info(f"[ResultFetcher] Fetching result for job: {job_id}")

        # Step 1: Job ì¡°íšŒ
        job = self.db.query(Job).filter(Job.id == job_id).first()
        if not job:
            raise AppException(
                status_code=404,
                error_code="E-AUTH-001",
                message="Job not found"
            )

        # Step 2: ë§Œë£Œ í™•ì¸
        if job.is_expired():
            raise AppException(
                status_code=410,
                error_code="E-AUTH-005",
                message="Job has expired"
            )

        # Step 3: íŒŒì¼ ì¡°íšŒ ë° Presigned URL ìƒì„±
        files = self._get_files_with_urls(job)

        # Step 4: ë¦¬í¬íŠ¸ ì¡°íšŒ
        report = self._get_report(job)

        # Step 5: ì‘ë‹µ ìƒì„±
        result = {
            "job_id": job.id,
            "status": job.status.value,
            "files": files,
            "report": report,
            "expires_at": job.expires_at
        }

        logger.info(f"[ResultFetcher] Result fetched successfully")

        return result

    def _get_files_with_urls(self, job: Job) -> list:
        """
        íŒŒì¼ ëª©ë¡ ì¡°íšŒ ë° Presigned URL ìƒì„±
        """
        files = []

        for job_file in job.files:
            # Presigned URL ìƒì„± (1ì‹œê°„ ìœ íš¨)
            presigned_url = self.s3_service.generate_presigned_url(
                job_file.s3_key,
                expiration=3600
            )

            files.append({
                "id": job_file.id,
                "file_type": job_file.file_type.value,
                "s3_key": job_file.s3_key,
                "presigned_url": presigned_url,
                "prediction_id": job_file.prediction_id,
                "seed": job_file.seed
            })

        # ì •ë ¬: original ë¨¼ì €, ê·¸ ë‹¤ìŒ generated (seed ìˆœ)
        files.sort(key=lambda x: (
            0 if x["file_type"] == "original" else 1,
            x["seed"] or 0
        ))

        return files

    def _get_report(self, job: Job) -> dict | None:
        """
        ë¦¬í¬íŠ¸ ì¡°íšŒ
        """
        if job.status != JobStatus.COMPLETED:
            return None

        report = self.db.query(Report).filter(
            Report.job_id == job.id
        ).first()

        if not report:
            return None

        # analysis_result íŒŒì‹±
        analysis_result = json.loads(report.analysis_result)

        # knowledge_items ë³€í™˜
        knowledge_items = [
            {
                "id": rk.knowledge_item.id,
                "title": rk.knowledge_item.title,
                "description": rk.knowledge_item.description,
                "procedure_type": rk.knowledge_item.procedure_type,
                "estimated_cost": rk.knowledge_item.estimated_cost
            }
            for rk in report.knowledge_items
        ]

        return {
            "id": report.id,
            "analysis_result": analysis_result,
            "knowledge_items": knowledge_items,
            "created_at": report.created_at.isoformat()
        }
```

---

## ğŸ” ì‚¬ìš© ì˜ˆì‹œ

### APIì—ì„œ ì‚¬ìš©

```python
from app.services.result_fetcher import ResultFetcher

@router.get("/results/{job_id}")
async def get_result(
    job_id: str,
    token: str = Depends(verify_token),
    db: Session = Depends(get_db)
):
    # í† í°ì—ì„œ job_id ì¶”ì¶œ ë° ê²€ì¦
    token_job_id = extract_job_id_from_token(token)
    if token_job_id != job_id:
        raise HTTPException(status_code=403, detail="Forbidden")

    # ê²°ê³¼ ì¡°íšŒ
    fetcher = ResultFetcher(db)
    result = fetcher.fetch_result(job_id)

    return result
```

---

## ğŸ” ì‘ë‹µ ì˜ˆì‹œ

```json
{
  "job_id": "job-uuid",
  "status": "completed",
  "files": [
    {
      "id": "file-uuid-1",
      "file_type": "original",
      "s3_key": "jobs/job-uuid/original/file-uuid-1.jpg",
      "presigned_url": "https://s3.amazonaws.com/...",
      "prediction_id": null,
      "seed": null
    },
    {
      "id": "file-uuid-2",
      "file_type": "generated",
      "s3_key": "jobs/job-uuid/generated/file-uuid-2.jpg",
      "presigned_url": "https://s3.amazonaws.com/...",
      "prediction_id": "pred-123",
      "seed": 42
    },
    {
      "id": "file-uuid-3",
      "file_type": "generated",
      "s3_key": "jobs/job-uuid/generated/file-uuid-3.jpg",
      "presigned_url": "https://s3.amazonaws.com/...",
      "prediction_id": "pred-124",
      "seed": 123
    },
    {
      "id": "file-uuid-4",
      "file_type": "generated",
      "s3_key": "jobs/job-uuid/generated/file-uuid-4.jpg",
      "presigned_url": "https://s3.amazonaws.com/...",
      "prediction_id": "pred-125",
      "seed": 456
    }
  ],
  "report": {
    "id": "report-uuid",
    "analysis_result": {
      "skin_tone": "uneven",
      "facial_features": ["dark_circles"],
      "improvement_areas": ["skin", "eyes"],
      "recommendations": ["vitamin_c", "eye_cream"]
    },
    "knowledge_items": [
      {
        "id": "item-uuid-1",
        "title": "ë¹„íƒ€ë¯¼ C ì„¸ëŸ¼",
        "description": "í”¼ë¶€ í†¤ì„ ë°ê²Œ...",
        "procedure_type": "cosmetic",
        "estimated_cost": "3ë§Œì›~10ë§Œì›"
      }
    ],
    "created_at": "2024-01-15T14:30:22.123456"
  },
  "expires_at": "2024-01-16T14:30:22.123456"
}
```

---

## âœ… í…ŒìŠ¤íŠ¸

```python
def test_fetch_result_success(db):
    # Job ìƒì„±
    from datetime import datetime
    from zoneinfo import ZoneInfo
    from app.config import settings

    def get_kst_now():
        return datetime.now(ZoneInfo(settings.TIMEZONE))

    job = Job(
        id=str(uuid.uuid4()),
        status=JobStatus.COMPLETED,
        expires_at=get_kst_now() + timedelta(hours=24)
    )
    db.add(job)

    # JobFile ìƒì„±
    job_file = JobFile(
        id=str(uuid.uuid4()),
        job_id=job.id,
        file_type=FileType.ORIGINAL,
        s3_key="test.jpg"
    )
    db.add(job_file)
    db.commit()

    # ê²°ê³¼ ì¡°íšŒ
    fetcher = ResultFetcher(db)
    result = fetcher.fetch_result(job.id)

    # ê²€ì¦
    assert result["job_id"] == job.id
    assert len(result["files"]) == 1
    assert result["files"][0]["presigned_url"] is not None


def test_fetch_result_expired(db):
    from datetime import datetime
    from zoneinfo import ZoneInfo
    from app.config import settings

    def get_kst_now():
        return datetime.now(ZoneInfo(settings.TIMEZONE))

    # ë§Œë£Œëœ Job
    job = Job(
        id=str(uuid.uuid4()),
        expires_at=get_kst_now() - timedelta(hours=1)
    )
    db.add(job)
    db.commit()

    # ê²°ê³¼ ì¡°íšŒ
    fetcher = ResultFetcher(db)

    with pytest.raises(AppException, match="E-AUTH-005"):
        fetcher.fetch_result(job.id)
```

---

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] app/services/result_fetcher.py ìƒì„±
- [ ] ResultFetcher í´ë˜ìŠ¤ êµ¬í˜„
- [ ] fetch_result() ë©”ì„œë“œ
- [ ] \_get_files_with_urls() ë©”ì„œë“œ
- [ ] \_get_report() ë©”ì„œë“œ
- [ ] í…ŒìŠ¤íŠ¸ ì‘ì„±

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

Result Fetcher ì™„ë£Œ â†’ **result API**
