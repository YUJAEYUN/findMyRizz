# LangChain Workflow (LangGraph)

## ğŸ“‹ ê°œìš”

LangGraphë¥¼ ì‚¬ìš©í•œ ë¦¬í¬íŠ¸ ìƒì„± Workflow êµ¬í˜„

---

## ğŸ¯ ëª©ì 

1. **êµ¬ì¡°í™”ëœ Workflow** - 3ê°œ ë…¸ë“œë¡œ ëª…í™•í•œ ë‹¨ê³„ ë¶„ë¦¬
2. **ìƒíƒœ ê´€ë¦¬** - TypedDict ê¸°ë°˜ ìƒíƒœ ì¶”ì 
3. **ì—ëŸ¬ ì²˜ë¦¬** - ê° ë…¸ë“œë³„ ì—ëŸ¬ í•¸ë“¤ë§
4. **LangSmith í†µí•©** - ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…

---

## ğŸ“ Workflow ì •ì˜

```python
# app/services/langchain_workflow.py

from typing import TypedDict, List, Optional, Annotated
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from pydantic import BaseModel, Field
import logging

logger = logging.getLogger(__name__)


# ===== State ì •ì˜ =====

class AnalysisResult(BaseModel):
    """GPT-4o Vision ë¶„ì„ ê²°ê³¼ (ìŠ¤í† ë¦¬í…”ë§ í˜•ì‹)"""
    title: str = Field(description="ë¦¬í¬íŠ¸ ì œëª© (ì˜ˆ: 'ë” ì„ ëª…í•œ ë‚˜ë¥¼ ë§Œë“œëŠ”, 3ê°€ì§€ ë³€í™”')")
    subtitle: str = Field(description="ë¶€ì œëª© (ì˜ˆ: 'ë‹¤ì´ì–´íŠ¸ 6Kg + í”¼ë¶€ ê´€ë¦¬ë¡œ ì™„ì„±í•œ Vë¼ì¸')")
    story_paragraphs: List[str] = Field(description="ìŠ¤í† ë¦¬í…”ë§ ë¬¸ë‹¨ ë¦¬ìŠ¤íŠ¸ (3-5ê°œ)")
    improvement_areas: List[str] = Field(description="ê°œì„  ì˜ì—­ íƒœê·¸ (ì˜ˆ: ['#ë‹¤ì´ì–´íŠ¸5Kg', '#Vë¼ì¸ì™„ì„±'])")
    confidence_score: float = Field(ge=0.0, le=1.0, description="ë¶„ì„ ì‹ ë¢°ë„")


class KnowledgeMatch(BaseModel):
    """ë§¤ì¹­ëœ Knowledge ì•„ì´í…œ (Polymorphic)"""
    item_id: str  # P001, SC001
    item_name: str
    item_type: str  # PROCEDURE, SELF_CARE
    category_name: str
    relevance_score: float
    match_reason: str
    effect_duration: Optional[str]
    cost_range: Optional[str]
    downtime: Optional[str]


class ReportState(TypedDict):
    """Workflow ìƒíƒœ"""
    # Input
    job_id: str
    image_urls: List[str]

    # Node 1: analyze_images
    analysis_result: Optional[AnalysisResult]

    # Node 2: match_knowledge
    matched_knowledge: List[KnowledgeMatch]

    # Node 3: generate_report
    report_id: str
    report_content: dict

    # Error handling
    error: Optional[str]
    step: str  # í˜„ì¬ ë‹¨ê³„


# ===== Node 1: ì´ë¯¸ì§€ ë¶„ì„ =====

async def analyze_images_node(state: ReportState) -> ReportState:
    """
    Node 1: GPT-4o Visionìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ì„

    Args:
        state: Workflow ìƒíƒœ

    Returns:
        ì—…ë°ì´íŠ¸ëœ ìƒíƒœ (analysis_result í¬í•¨)
    """
    logger.info(f"[Node 1] Starting image analysis for job_id={state['job_id']}")

    try:
        # Step 1: LLM ì´ˆê¸°í™” (Structured Output)
        llm = ChatOpenAI(
            model="gpt-4o",
            temperature=0.3,
            max_tokens=2000
        )
        structured_llm = llm.with_structured_output(AnalysisResult)

        # Step 2: í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ë‹¹ì‹ ì€ ì™¸ëª¨ ë¶„ì„ ì „ë¬¸ê°€ì´ì ìŠ¤í† ë¦¬í…”ëŸ¬ì…ë‹ˆë‹¤. ì œê³µëœ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤í† ë¦¬í…”ë§ í˜•ì‹ì˜ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

**ë¦¬í¬íŠ¸ êµ¬ì„±:**

1. **title**: ë§¤ë ¥ì ì¸ ì œëª© (ì˜ˆ: "ë” ì„ ëª…í•œ ë‚˜ë¥¼ ë§Œë“œëŠ”, 3ê°€ì§€ ë³€í™”")
2. **subtitle**: êµ¬ì²´ì ì¸ ë¶€ì œëª© (ì˜ˆ: "ë‹¤ì´ì–´íŠ¸ 6Kg + í”¼ë¶€ ê´€ë¦¬ë¡œ ì™„ì„±í•œ Vë¼ì¸")
3. **story_paragraphs**: 3-5ê°œì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±ëœ ìŠ¤í† ë¦¬
   - ì²« ë¬¸ë‹¨: í˜„ì¬ ë‹¹ì‹ ì˜ ì–¼êµ´ ë¶„ì„ (ê¸ì •ì  + ê°œì„ ì )
   - ì¤‘ê°„ ë¬¸ë‹¨ë“¤: ê° ê°œì„  ì˜ì—­ë³„ êµ¬ì²´ì ì¸ ê´€ì°°ê³¼ ì œì•ˆ
   - ë§ˆì§€ë§‰ ë¬¸ë‹¨: ê²©ë ¤ì™€ ê¸°ëŒ€íš¨ê³¼
4. **improvement_areas**: í•´ì‹œíƒœê·¸ í˜•ì‹ì˜ ê°œì„  ì˜ì—­ (ì˜ˆ: ["#ë‹¤ì´ì–´íŠ¸5Kg", "#Vë¼ì¸ì™„ì„±", "#í„±ì„ ì •ë¦¬", "#ë ˆì´ì €í† ë‹", "#ê¸°ì´ˆí™”ì¥"])
5. **confidence_score**: ë¶„ì„ ì‹ ë¢°ë„ (0.0 ~ 1.0)

**ìŠ¤í† ë¦¬í…”ë§ ê°€ì´ë“œ:**
- ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ ì‚¬ìš©
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ì˜ˆì‹œ í¬í•¨ (ì˜ˆ: "5kg ê°ëŸ‰", "í”¼ë¶€í†¤ 23% ê°œì„ ")
- ë¶€ì •ì  í‘œí˜„ ëŒ€ì‹  ê¸ì •ì  ë³€í™” ê°•ì¡°
- ì‹¤í˜„ ê°€ëŠ¥í•œ ëª©í‘œ ì œì‹œ

ì´ë¯¸ì§€ URL: {state['image_urls']}
"""

        # Step 3: ì´ë¯¸ì§€ í¬í•¨ ë©”ì‹œì§€ ìƒì„±
        messages = [
            HumanMessage(
                content=[
                    {"type": "text", "text": prompt},
                    *[
                        {"type": "image_url", "image_url": {"url": url}}
                        for url in state['image_urls']
                    ]
                ]
            )
        ]

        # Step 4: LLM í˜¸ì¶œ
        logger.info(f"[Node 1] Calling GPT-4o Vision with {len(state['image_urls'])} images")
        analysis_result = await structured_llm.ainvoke(messages)

        # Step 5: ìƒíƒœ ì—…ë°ì´íŠ¸
        state['analysis_result'] = analysis_result
        state['step'] = 'analyze_images_completed'

        logger.info(f"[Node 1] Analysis completed. Title: {analysis_result.title}")
        return state

    except Exception as e:
        logger.error(f"[Node 1] Error: {str(e)}", exc_info=True)
        state['error'] = f"Image analysis failed: {str(e)}"
        state['step'] = 'analyze_images_failed'
        return state


# ===== Node 2: Knowledge ë§¤ì¹­ =====

async def match_knowledge_node(state: ReportState) -> ReportState:
    """
    Node 2: RAGë¡œ Knowledge Base ë§¤ì¹­

    Args:
        state: Workflow ìƒíƒœ

    Returns:
        ì—…ë°ì´íŠ¸ëœ ìƒíƒœ (matched_knowledge í¬í•¨)
    """
    logger.info(f"[Node 2] Starting knowledge matching for job_id={state['job_id']}")

    # ì´ì „ ë…¸ë“œ ì‹¤íŒ¨ ì‹œ ìŠ¤í‚µ
    if state.get('error'):
        logger.warning(f"[Node 2] Skipping due to previous error")
        return state

    try:
        from app.services.knowledge_retriever import KnowledgeRetriever

        # Step 1: Retriever ì´ˆê¸°í™”
        retriever = KnowledgeRetriever()

        # Step 2: ê°œì„  ì˜ì—­ë³„ë¡œ Knowledge ê²€ìƒ‰
        analysis = state['analysis_result']
        all_matches = []

        for area in analysis.improvement_areas:
            logger.info(f"[Node 2] Searching knowledge for area: {area}")

            # Step 3: RAG ê²€ìƒ‰
            matches = await retriever.search(
                query=area,
                observations=analysis.specific_observations.get(area, ""),
                top_k=3
            )

            all_matches.extend(matches)

        # Step 4: ì¤‘ë³µ ì œê±° ë° ì •ë ¬ (relevance_score ê¸°ì¤€)
        unique_matches = {m.item_id: m for m in all_matches}
        sorted_matches = sorted(
            unique_matches.values(),
            key=lambda x: x.relevance_score,
            reverse=True
        )[:10]  # ìƒìœ„ 10ê°œ

        # Step 5: ìƒíƒœ ì—…ë°ì´íŠ¸
        state['matched_knowledge'] = sorted_matches
        state['step'] = 'match_knowledge_completed'

        logger.info(f"[Node 2] Matched {len(sorted_matches)} knowledge items")
        return state

    except Exception as e:
        logger.error(f"[Node 2] Error: {str(e)}", exc_info=True)
        state['error'] = f"Knowledge matching failed: {str(e)}"
        state['step'] = 'match_knowledge_failed'
        return state


# ===== Node 3: ë¦¬í¬íŠ¸ ìƒì„± =====

async def generate_report_node(state: ReportState) -> ReportState:
    """
    Node 3: ë¦¬í¬íŠ¸ ìƒì„± ë° DB ì €ì¥

    Args:
        state: Workflow ìƒíƒœ

    Returns:
        ì—…ë°ì´íŠ¸ëœ ìƒíƒœ (report_id, report_content í¬í•¨)
    """
    logger.info(f"[Node 3] Starting report generation for job_id={state['job_id']}")

    # ì´ì „ ë…¸ë“œ ì‹¤íŒ¨ ì‹œ ìŠ¤í‚µ
    if state.get('error'):
        logger.warning(f"[Node 3] Skipping due to previous error")
        return state

    try:
        from app.services.report_builder import ReportBuilder
        from app.core.database import get_db

        # Step 1: ReportBuilder ì´ˆê¸°í™”
        builder = ReportBuilder()

        # Step 2: ë¦¬í¬íŠ¸ ìƒì„±
        async with get_db() as db:
            report = await builder.create_report(
                db=db,
                job_id=state['job_id'],
                analysis_result=state['analysis_result'],
                matched_knowledge=state['matched_knowledge']
            )

        # Step 3: ìƒíƒœ ì—…ë°ì´íŠ¸
        state['report_id'] = str(report.report_id)
        state['report_content'] = report.to_dict()
        state['step'] = 'generate_report_completed'

        logger.info(f"[Node 3] Report created: {report.report_id}")
        return state

    except Exception as e:
        logger.error(f"[Node 3] Error: {str(e)}", exc_info=True)
        state['error'] = f"Report generation failed: {str(e)}"
        state['step'] = 'generate_report_failed'
        return state


# ===== Workflow êµ¬ì„± =====

def create_report_workflow() -> StateGraph:
    """
    ë¦¬í¬íŠ¸ ìƒì„± Workflow ìƒì„±

    Returns:
        LangGraph StateGraph
    """
    # Step 1: Graph ì´ˆê¸°í™”
    workflow = StateGraph(ReportState)

    # Step 2: ë…¸ë“œ ì¶”ê°€
    workflow.add_node("analyze_images", analyze_images_node)
    workflow.add_node("match_knowledge", match_knowledge_node)
    workflow.add_node("generate_report", generate_report_node)

    # Step 3: ì—£ì§€ ì •ì˜
    workflow.set_entry_point("analyze_images")
    workflow.add_edge("analyze_images", "match_knowledge")
    workflow.add_edge("match_knowledge", "generate_report")
    workflow.add_edge("generate_report", END)

    # Step 4: ì»´íŒŒì¼
    return workflow.compile()


# ===== ì‹¤í–‰ í•¨ìˆ˜ =====

async def run_report_workflow(
    job_id: str,
    image_urls: List[str]
) -> dict:
    """
    ë¦¬í¬íŠ¸ ìƒì„± Workflow ì‹¤í–‰

    Args:
        job_id: Job ID
        image_urls: ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸

    Returns:
        ìµœì¢… ìƒíƒœ ë”•ì…”ë„ˆë¦¬

    Raises:
        Exception: Workflow ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ
    """
    logger.info(f"Starting report workflow for job_id={job_id}")

    # Step 1: ì´ˆê¸° ìƒíƒœ ìƒì„±
    initial_state = ReportState(
        job_id=job_id,
        image_urls=image_urls,
        analysis_result=None,
        matched_knowledge=[],
        report_id="",
        report_content={},
        error=None,
        step="initialized"
    )

    # Step 2: Workflow ìƒì„±
    workflow = create_report_workflow()

    # Step 3: ì‹¤í–‰
    final_state = await workflow.ainvoke(initial_state)

    # Step 4: ì—ëŸ¬ ì²´í¬
    if final_state.get('error'):
        logger.error(f"Workflow failed at step={final_state['step']}: {final_state['error']}")
        raise Exception(final_state['error'])

    logger.info(f"Workflow completed successfully. Report ID: {final_state['report_id']}")
    return final_state
```

---

## ğŸ“ ë¦¬í¬íŠ¸ ì˜ˆì‹œ

### ì…ë ¥ ì´ë¯¸ì§€

- ì‚¬ìš©ì ì–¼êµ´ ì‚¬ì§„ (ì •ë©´, ì¸¡ë©´ ë“±)

### ì¶œë ¥ ë¦¬í¬íŠ¸

```json
{
  "title": "ë” ì„ ëª…í•œ ë‚˜ë¥¼ ë§Œë“œëŠ”, 3ê°€ì§€ ë³€í™”",
  "subtitle": "ë‹¤ì´ì–´íŠ¸ 6Kg + í”¼ë¶€ ê´€ë¦¬ë¡œ ì™„ì„±í•œ Vë¼ì¸",
  "story_paragraphs": [
    "í˜„ì¬ ë‹¹ì‹ ì˜ ì–¼êµ´ì€ ì•½ê°„ì˜ ë¶€ì¢…ê³¼ ì§€ë°©ì¸µìœ¼ë¡œ ì¸í•´ ë³¸ë˜ì˜ ë‚ ì¹´ë¡œìš´ ìœ¤ê³½ì´ ìˆ¨ê²¨ì ¸ ìˆëŠ” ìƒíƒœì…ë‹ˆë‹¤. íŠ¹íˆ í„±ì„ ì´ ë¶ˆë¶„ëª…í•˜ê³  ë³¼ì— ë‘¥ê¸€ê²Œ ì§€ë°©ì´ ë¶„í¬ë˜ì–´ ìˆì–´ ì „ì²´ì ìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ ì¸ìƒì„ ì¤ë‹ˆë‹¤.",
    "ì²´ê³„ì ì¸ ë‹¤ì´ì–´íŠ¸ë¥¼ í†µí•´ 5kg ê°ëŸ‰ì„ ëª©í‘œë¡œ í•˜ë©´ ì–¼êµ´ ì§€ë°©ì¸µì´ ìì—°ìŠ¤ëŸ½ê²Œ ê°ì†Œí•˜ë©° Vë¼ì¸ì´ ë“œëŸ¬ë‚  ê²ƒì…ë‹ˆë‹¤. ë• ì•„ë˜ ì§€ë°©ì´ ê°ì†Œí•˜ë©´ì„œ ëª© í„±ì„ ì´ ê°ì§€ê²Œ ì„ ëª…í•´ì§€ê³ , ê´‘ëŒ€ë¼ˆê°€ ì‚´ì§ ë“œëŸ¬ë‚˜ì§€ë©´ì„œ ì…ì²´ê°ì´ ì‚´ì•„ë‚©ë‹ˆë‹¤.",
    "ë• ì•„ë˜ ì§€ë°©ì´ ê°ì†Œí•˜ë©´ì„œ ëª© í„±ì„ ì´ ê°ì§€ê²Œ ì„ ëª…í•´ì§€ê³ , ê´‘ëŒ€ë¼ˆê°€ ì‚´ì§ ë“œëŸ¬ë‚˜ì§€ë©´ì„œ ì…ì²´ê°ì´ ì‚´ì•„ë‚©ë‹ˆë‹¤. ì˜í•™ ì—°êµ¬ì— ë”°ë¥´ë©´ 5kg ì²´ì¤‘ ê°ëŸ‰ ì‹œ ì–¼êµ´ ì§€ë°©ì€ í‰ê·  23% ê°ì†Œí•˜ë©°, í„±ì„ ë„ ì•½ 12-15ë„ ë” ë‚ ì¹´ë¡œì›Œì§‘ë‹ˆë‹¤.",
    "ì—¬ê¸°ì— ê¸°ì´ˆì ì¸ í”¼ë¶€ ê´€ë¦¬ë¥¼ ë”í•˜ë©´ ì™„ë²½í•©ë‹ˆë‹¤. ë ˆì´ì € í† ë‹ìœ¼ë¡œ ìƒ‰ì†Œë¥¼ ê°œì„ í•˜ê³  ê¸°ì´ˆ í™”ì¥ìœ¼ë¡œ í”¼ë¶€ê²°ì„ ì •ëˆí•˜ë©´, ê±´ê°•í•˜ê³  ê¹¨ë—í•œ ì¸ìƒì´ ì™„ì„±ë©ë‹ˆë‹¤. ê°„ë‹¨í•œ ê´€ë¦¬ì§€ë§Œ ì „ì²´ì ì¸ ì™„ì„±ë„ë¥¼ ë†’ì—¬ì¤„ ê²ƒì…ë‹ˆë‹¤."
  ],
  "improvement_areas": [
    "#ë‹¤ì´ì–´íŠ¸5Kg",
    "#Vë¼ì¸ì™„ì„±",
    "#í„±ì„ ì •ë¦¬",
    "#ë ˆì´ì €í† ë‹",
    "#ê¸°ì´ˆí™”ì¥"
  ],
  "confidence_score": 0.85
}
```

---

## ğŸ” ì‚¬ìš© ì˜ˆì‹œ

```python
# app/api/v1/jobs.py

from app.services.langchain_workflow import run_report_workflow

@router.post("/{job_id}/generate-report")
async def generate_report(job_id: str):
    """ë¦¬í¬íŠ¸ ìƒì„± API"""

    # Step 1: Job ì¡°íšŒ
    job = await get_job(job_id)

    # Step 2: ì´ë¯¸ì§€ URL ìˆ˜ì§‘
    image_urls = [file.s3_url for file in job.files if file.file_type == "generated"]

    # Step 3: Workflow ì‹¤í–‰
    try:
        result = await run_report_workflow(
            job_id=job_id,
            image_urls=image_urls
        )

        return {"report_id": result['report_id']}

    except Exception as e:
        logger.error(f"Report generation failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))
```

---

## ğŸ“š ì°¸ê³ 

- `docs/technical/langchain_architecture.md` - ì•„í‚¤í…ì²˜ ìƒì„¸ ì„¤ëª…
- ë‹¤ìŒ ë¬¸ì„œ: `knowledge-retriever.md` - RAG Retriever êµ¬í˜„
