# LangGraph ì•„í‚¤í…ì²˜ ì„¤ê³„ (ë¦¬í¬íŠ¸ ìƒì„±)

## ğŸ“‹ ê°œìš”

ë‹¨ìˆœ OpenAI API í˜¸ì¶œì´ ì•„ë‹Œ, **LangGraph ê¸°ë°˜ RAG (Retrieval-Augmented Generation)** íŒ¨í„´ìœ¼ë¡œ ë¦¬í¬íŠ¸ ìƒì„± ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

**í•µì‹¬ ê¸°ìˆ  ìŠ¤íƒ:**

- **LangGraph**: ìƒíƒœ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ (ë©”ì¸)
- **LangChain**: LLM í†µí•© ë° í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ (ë³´ì¡°)
- **LangSmith**: ì „ì²´ í”„ë¡œì„¸ìŠ¤ ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…

---

## ğŸ¯ ì„¤ê³„ ëª©í‘œ

1. **Knowledge Base í™œìš©**: DBì˜ êµ¬ì¡°í™”ëœ ì§€ì‹ì„ LLMì— íš¨ê³¼ì ìœ¼ë¡œ ì „ë‹¬
2. **ì¼ê´€ì„± ë³´ì¥**: ì²´ê³„ì ì¸ ì›Œí¬í”Œë¡œìš°ë¡œ ë¦¬í¬íŠ¸ í’ˆì§ˆ ìœ ì§€
3. **í™•ì¥ì„±**: ìƒˆë¡œìš´ ë¶„ì„ ë‹¨ê³„ ì¶”ê°€ ìš©ì´
4. **ì¶”ì  ê°€ëŠ¥ì„±**: LangSmithë¡œ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ëª¨ë‹ˆí„°ë§

---

## ğŸ—ï¸ ì „ì²´ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LangGraph Workflow                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  Image   â”‚â”€â”€â”€â–¶â”‚ Analysis â”‚â”€â”€â”€â–¶â”‚ Knowledgeâ”‚              â”‚
â”‚  â”‚ Analysis â”‚    â”‚ Parsing  â”‚    â”‚ Matching â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚       â”‚               â”‚                 â”‚                    â”‚
â”‚       â–¼               â–¼                 â–¼                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ GPT-4o   â”‚    â”‚ Pydantic â”‚    â”‚   RAG    â”‚              â”‚
â”‚  â”‚  Vision  â”‚    â”‚  Parser  â”‚    â”‚ Retrieverâ”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                        â”‚                     â”‚
â”‚                                        â–¼                     â”‚
â”‚                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚                                  â”‚PostgreSQLâ”‚               â”‚
â”‚                                  â”‚Knowledge â”‚               â”‚
â”‚                                  â”‚   Base   â”‚               â”‚
â”‚                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Report   â”‚â—€â”€â”€â”€â”‚ Content  â”‚â—€â”€â”€â”€â”‚ Template â”‚              â”‚
â”‚  â”‚Generationâ”‚    â”‚ Builder  â”‚    â”‚ Selector â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ ê¸°ìˆ  ìŠ¤íƒ

```python
# requirements.txt ì¶”ê°€
langchain==0.1.0
langchain-openai==0.0.5
langchain-community==0.0.20
langgraph==0.0.20
langsmith==0.0.77

# Vector Store (í–¥í›„)
pgvector==0.2.4
langchain-postgres==0.0.3
```

---

## ğŸ”„ LangGraph Workflow ì„¤ê³„

### 1. State ì •ì˜

```python
from typing import TypedDict, List, Optional
from pydantic import BaseModel

class AnalysisResult(BaseModel):
    """GPT-4o Vision ë¶„ì„ ê²°ê³¼"""
    overall_impression: str
    improvement_areas: List[str]  # ['í”¼ë¶€', 'ìœ¤ê³½', 'ëˆˆ', 'ì½”', 'ì…ìˆ ']
    specific_observations: dict   # {'í”¼ë¶€': 'ëª¨ê³µì´ ë³´ì„', 'ìœ¤ê³½': 'Vë¼ì¸ í•„ìš”'}
    confidence_score: float       # 0.0 ~ 1.0

class KnowledgeMatch(BaseModel):
    """ë§¤ì¹­ëœ Knowledge ì•„ì´í…œ (Polymorphic)"""
    item_id: str  # P001, SC001
    item_name: str
    item_type: str  # PROCEDURE, SELF_CARE
    category_name: str
    relevance_score: float
    match_reason: str
    effect_duration: Optional[str]
    cost_range: Optional[str]
    downtime: Optional[str]

class ReportState(TypedDict):
    """LangGraph State"""
    # Input
    job_id: str
    image_urls: List[str]  # 3ê°œ ìƒì„± ì´ë¯¸ì§€

    # Intermediate
    analysis_result: Optional[AnalysisResult]
    matched_knowledge: List[KnowledgeMatch]

    # Output
    report_id: str
    report_content: dict

    # Metadata
    error: Optional[str]
    step: str
```

### 2. Graph ë…¸ë“œ ì •ì˜

```python
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

# ============================================
# Node 1: Image Analysis (GPT-4o Vision)
# ============================================
async def analyze_images_node(state: ReportState) -> ReportState:
    """
    3ê°œ ì´ë¯¸ì§€ë¥¼ GPT-4o Visionìœ¼ë¡œ ë¶„ì„

    Returns:
        AnalysisResult with structured output
    """
    llm = ChatOpenAI(
        model="gpt-4o",
        temperature=0.3,
        max_tokens=2000
    )

    # Structured Output with Pydantic
    structured_llm = llm.with_structured_output(AnalysisResult)

    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ì „ë¬¸ í”¼ë¶€ê³¼ ì˜ì‚¬ì´ì ë¯¸ìš© ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ AI ìƒì„± ì´ë¯¸ì§€ 3ì¥ì„ ë¶„ì„í•˜ì—¬:
1. ì „ì²´ì ì¸ ì¸ìƒ
2. ê°œì„ ì´ í•„ìš”í•œ ì˜ì—­ (í”¼ë¶€, ìœ¤ê³½, ëˆˆ, ì½”, ì…ìˆ  ì¤‘ ì„ íƒ)
3. ê° ì˜ì—­ë³„ êµ¬ì²´ì ì¸ ê´€ì°° ì‚¬í•­
4. ë¶„ì„ ì‹ ë¢°ë„

ë¥¼ ì œê³µí•˜ì„¸ìš”.

**ì¤‘ìš”**: ê³¼ì¥í•˜ì§€ ë§ê³  í˜„ì‹¤ì ì´ê³  ë‹¬ì„± ê°€ëŠ¥í•œ ê°œì„  ì‚¬í•­ë§Œ ì–¸ê¸‰í•˜ì„¸ìš”."""),
        ("user", [
            {"type": "text", "text": "ë‹¤ìŒ 3ì¥ì˜ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:"},
            {"type": "image_url", "image_url": {"url": state["image_urls"][0]}},
            {"type": "image_url", "image_url": {"url": state["image_urls"][1]}},
            {"type": "image_url", "image_url": {"url": state["image_urls"][2]}},
        ])
    ])

    chain = prompt | structured_llm

    try:
        result = await chain.ainvoke({})
        state["analysis_result"] = result
        state["step"] = "analysis_complete"
    except Exception as e:
        state["error"] = f"Image analysis failed: {str(e)}"
        state["step"] = "error"

    return state


# ============================================
# Node 2: Knowledge Matching (RAG)
# ============================================
async def match_knowledge_node(state: ReportState) -> ReportState:
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Knowledge Baseì—ì„œ ê´€ë ¨ í•­ëª© ê²€ìƒ‰

    Uses:
        - Semantic search (í–¥í›„ Vector Store)
        - Metadata filtering
        - Relevance scoring
    """
    from app.services.knowledge_retriever import KnowledgeRetriever

    retriever = KnowledgeRetriever()
    analysis = state["analysis_result"]

    matched_items = []

    # Step 1: ê°œì„  ì˜ì—­ë³„ë¡œ Knowledge ê²€ìƒ‰ (Polymorphic)
    for area in analysis.improvement_areas:
        # ì˜ˆ: area = 'í”¼ë¶€'
        observation = analysis.specific_observations.get(area, "")

        # ì‹œìˆ  ê²€ìƒ‰
        procedures = await retriever.search(
            query=area,
            observations=observation,
            item_type="PROCEDURE",
            top_k=3
        )
        matched_items.extend(procedures)

        # ìê¸°ê´€ë¦¬ ê²€ìƒ‰
        self_care = await retriever.search(
            query=area,
            observations=observation,
            item_type="SELF_CARE",
            top_k=2
        )
        matched_items.extend(self_care)

    # Step 3: Relevance scoreë¡œ ì •ë ¬ ë° ì¤‘ë³µ ì œê±°
    unique_items = {}
    for item in matched_items:
        if item.item_id not in unique_items:
            unique_items[item.item_id] = item
        elif item.relevance_score > unique_items[item.item_id].relevance_score:
            unique_items[item.item_id] = item

    state["matched_knowledge"] = sorted(
        unique_items.values(),
        key=lambda x: x.relevance_score,
        reverse=True
    )[:10]  # ìµœëŒ€ 10ê°œ

    state["step"] = "matching_complete"
    return state


# ============================================
# Node 3: Report Generation
# ============================================
async def generate_report_node(state: ReportState) -> ReportState:
    """
    ë¶„ì„ ê²°ê³¼ + ë§¤ì¹­ëœ Knowledgeë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¦¬í¬íŠ¸ ìƒì„±
    """
    from app.services.report_builder import ReportBuilder

    builder = ReportBuilder()

    report_content = await builder.build(
        analysis=state["analysis_result"],
        knowledge_items=state["matched_knowledge"]
    )

    # DBì— ì €ì¥
    from app.models.report import Report
    from app.core.database import get_db

    async with get_db() as db:
        report = Report(
            job_id=state["job_id"],
            analysis_summary=state["analysis_result"].overall_impression,
            improvement_areas=state["analysis_result"].improvement_areas,
        )
        db.add(report)
        await db.commit()

        # Knowledge ë§¤ì¹­ ì €ì¥ (Polymorphic)
        for idx, item in enumerate(state["matched_knowledge"]):
            mapping = ReportKnowledgeItem(
                report_id=report.report_id,
                item_id=item.item_id,  # P001, SC001
                item_type=item.item_type,  # PROCEDURE, SELF_CARE
                relevance_score=item.relevance_score,
                match_reason=item.match_reason,
                display_order=idx + 1
            )
            db.add(mapping)

        await db.commit()

        state["report_id"] = str(report.report_id)
        state["report_content"] = report_content
        state["step"] = "complete"

    return state


# ============================================
# Graph êµ¬ì„±
# ============================================
def create_report_workflow() -> StateGraph:
    """LangGraph Workflow ìƒì„±"""

    workflow = StateGraph(ReportState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("analyze_images", analyze_images_node)
    workflow.add_node("match_knowledge", match_knowledge_node)
    workflow.add_node("generate_report", generate_report_node)

    # ì—£ì§€ ì •ì˜
    workflow.set_entry_point("analyze_images")

    workflow.add_conditional_edges(
        "analyze_images",
        lambda state: "error" if state.get("error") else "continue",
        {
            "continue": "match_knowledge",
            "error": END
        }
    )

    workflow.add_edge("match_knowledge", "generate_report")
    workflow.add_edge("generate_report", END)

    return workflow.compile()
```

---

## ğŸ” Knowledge Retriever (RAG)

```python
# app/services/knowledge_retriever.py

from typing import List, Dict, Optional
from sqlalchemy import select, and_, or_
from sqlalchemy.ext.asyncio import AsyncSession

class KnowledgeRetriever:
    """Knowledge Base RAG Retriever"""

    def __init__(self, db: AsyncSession):
        self.db = db

    async def search(
        self,
        query: str,
        filters: Optional[Dict] = None,
        top_k: int = 5
    ) -> List[KnowledgeMatch]:
        """
        Semantic search + Metadata filtering

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬ (ì˜ˆ: "í”¼ë¶€ ê°œì„ : ëª¨ê³µì´ ë³´ì„")
            filters: ë©”íƒ€ë°ì´í„° í•„í„° (ì˜ˆ: {"category_type": "procedure"})
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê°œìˆ˜

        Returns:
            ë§¤ì¹­ëœ Knowledge ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸
        """
        # Step 1: Keyword matching (í˜„ì¬)
        # í–¥í›„: Vector Storeë¡œ ì—…ê·¸ë ˆì´ë“œ

        stmt = select(KBItem).where(KBItem.is_active == True)

        # Filters ì ìš©
        if filters:
            if "category_type" in filters:
                stmt = stmt.join(KBCategory).where(
                    KBCategory.category_type == filters["category_type"]
                )
            if "difficulty_level" in filters:
                stmt = stmt.join(KBSelfCareDetails).where(
                    KBSelfCareDetails.difficulty_level == filters["difficulty_level"]
                )

        # Keyword search (ê°„ë‹¨í•œ ë²„ì „)
        keywords = self._extract_keywords(query)
        if keywords:
            conditions = [
                or_(
                    KBItem.name.ilike(f"%{kw}%"),
                    KBItem.description.ilike(f"%{kw}%")
                )
                for kw in keywords
            ]
            stmt = stmt.where(or_(*conditions))

        result = await self.db.execute(stmt.limit(top_k))
        items = result.scalars().all()

        # Step 2: Relevance scoring
        matches = []
        for item in items:
            score = self._calculate_relevance(query, item)
            matches.append(KnowledgeMatch(
                item_id=item.item_id,
                item_code=item.item_code,
                item_name=item.name,
                item_type=item.item_type,
                relevance_score=score,
                match_reason=self._generate_match_reason(query, item)
            ))

        return sorted(matches, key=lambda x: x.relevance_score, reverse=True)

    def _extract_keywords(self, query: str) -> List[str]:
        """ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ ë²„ì „: ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬
        # í–¥í›„: í˜•íƒœì†Œ ë¶„ì„ê¸° (KoNLPy) ì‚¬ìš©
        return [w for w in query.split() if len(w) > 1]

    def _calculate_relevance(self, query: str, item: KBItem) -> float:
        """Relevance score ê³„ì‚° (0.0 ~ 1.0)"""
        score = 0.0
        keywords = self._extract_keywords(query)

        for kw in keywords:
            if kw in item.name:
                score += 0.5
            if kw in (item.description or ""):
                score += 0.3

        return min(score, 1.0)

    def _generate_match_reason(self, query: str, item: KBItem) -> str:
        """ë§¤ì¹­ ì´ìœ  ìƒì„±"""
        return f"'{query}'ì™€ ê´€ë ¨ëœ {item.item_type} í•­ëª©"
```

---

## ğŸ“Š LangSmith í†µí•©

```python
# app/core/config.py

class Settings(BaseSettings):
    # ... ê¸°ì¡´ ì„¤ì •

    # LangSmith
    LANGCHAIN_TRACING_V2: bool = True
    LANGCHAIN_API_KEY: str
    LANGCHAIN_PROJECT: str = "find-my-rizz"
```

```python
# app/services/report_service.py

from langsmith import traceable

@traceable(name="generate_report_full_workflow")
async def generate_report(job_id: str) -> dict:
    """
    ì „ì²´ ë¦¬í¬íŠ¸ ìƒì„± ì›Œí¬í”Œë¡œìš°

    LangSmithë¡œ ì¶”ì ë¨
    """
    workflow = create_report_workflow()

    # ì´ë¯¸ì§€ URL ê°€ì ¸ì˜¤ê¸°
    image_urls = await get_generated_image_urls(job_id)

    # Workflow ì‹¤í–‰
    result = await workflow.ainvoke({
        "job_id": job_id,
        "image_urls": image_urls,
        "step": "start"
    })

    return result
```

---

## ğŸš€ í–¥í›„ ê³ ë„í™”

### 1. Vector Store ë„ì…

```python
from langchain_postgres import PGVector

# pgvector í™•ì¥ ì„¤ì¹˜
# CREATE EXTENSION vector;

embeddings = OpenAIEmbeddings()

vector_store = PGVector(
    connection_string=settings.DATABASE_URL,
    embedding_function=embeddings,
    collection_name="knowledge_base"
)

# Knowledge ì„ë² ë”© ìƒì„±
for item in kb_items:
    vector_store.add_texts(
        texts=[f"{item.name}: {item.description}"],
        metadatas=[{
            "item_id": item.item_id,
            "item_type": item.item_type,
            "category_id": item.category_id
        }]
    )
```

### 2. Multi-Agent ì‹œìŠ¤í…œ

```python
# ì „ë¬¸ê°€ Agentë“¤
skin_expert = create_agent("í”¼ë¶€ ì „ë¬¸ê°€")
contour_expert = create_agent("ìœ¤ê³½ ì „ë¬¸ê°€")
eye_expert = create_agent("ëˆˆ ì „ë¬¸ê°€")

# Supervisor Agent
supervisor = create_supervisor([skin_expert, contour_expert, eye_expert])
```

---

## âœ… ì¥ì 

1. **ì²´ê³„ì ì¸ ì›Œí¬í”Œë¡œìš°**: LangGraphë¡œ ëª…í™•í•œ ë‹¨ê³„ ì •ì˜
2. **Knowledge í™œìš©**: DBì˜ êµ¬ì¡°í™”ëœ ì§€ì‹ì„ íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ìš©
3. **ì¶”ì  ê°€ëŠ¥ì„±**: LangSmithë¡œ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ëª¨ë‹ˆí„°ë§
4. **í™•ì¥ì„±**: ìƒˆë¡œìš´ ë…¸ë“œ ì¶”ê°€ ìš©ì´
5. **ì¼ê´€ì„±**: Pydanticìœ¼ë¡œ íƒ€ì… ì•ˆì •ì„± ë³´ì¥
